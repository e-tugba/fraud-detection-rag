# -*- coding: utf-8 -*-
"""Fraud_Detection_Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14aGYvqODhLGrxYBbmKvIEZRpy9CRj3ZG

## ğŸ’³ GeliÅŸmiÅŸ Kredi KartÄ± DolandÄ±rÄ±cÄ±lÄ±k Analizi Chatbotu

Bu proje, kredi kartÄ± iÅŸlemlerinde dolandÄ±rÄ±cÄ±lÄ±k tespiti iÃ§in geliÅŸtirilmiÅŸ bilgi tabanÄ± destekli bir chatbot sistemidir.  
Model: `google/flan-t5-small`  
GeliÅŸtirici: **TuÄŸba Bayar**  
CanlÄ± demo: [https://huggingface.co/spaces/bayar1/fraud-detection-rag](https://huggingface.co/spaces/bayar1/fraud-detection-rag)
"""

import pandas as pd
df = pd.read_csv('creditcard.csv')
df.head()

import pandas as pd
df = pd.read_csv('/content/creditcard.csv')
print("Shape:", df.shape)
print(df['Class'].value_counts())
print(df.describe().T)


counts = df['Class'].value_counts(normalize=True)
print("Class distribution (fraud=1):\n", counts)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

X = df.drop(columns=['Class'])
y = df['Class']


scaler = StandardScaler()
X['Amount'] = scaler.fit_transform(X[['Amount']])

X['Time'] = scaler.fit_transform(X[['Time']])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Train shape:", X_train.shape, y_train.value_counts(normalize=True))
print("Test shape:", X_test.shape, y_test.value_counts(normalize=True))

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)
print("After SMOTE:", y_train_res.value_counts())

import lightgbm as lgb
from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support

train_data = lgb.Dataset(X_train_res, label=y_train_res)
params = {
    'objective': 'binary',
    'metric': 'auc',
    'boosting_type': 'gbdt',
    'verbosity': -1,
    'seed': 42
}
model = lgb.train(params, train_data, num_boost_round=200)


y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

print("AUC:", roc_auc_score(y_test, y_pred_prob))
print(classification_report(y_test, y_pred, digits=4))

import joblib
joblib.dump(model, 'lgb_fraud_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("Model ve scaler kaydedildi.")

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve

fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('ROC Curve')
plt.show()

# HÃ¼cre 7: knowledge documents oluÅŸturma
kb_texts = []

# 1) dataset description
kb_texts.append("""
Credit Card Fraud Detection dataset from Kaggle (V1..V28 anonymized features).
Target is 'Class' where 1 indicates fraud. There is severe class imbalance: fraud ~0.172%.
Features: Time, Amount, V1..V28 (PCA components).
Preprocessing used: StandardScaler on Amount and Time.
""")

# 2) model performance summary
kb_texts.append(f"""
Model: LightGBM
AUC: {roc_auc_score(y_test, y_pred_prob):.4f}
Classification report:
{classification_report(y_test, y_pred, digits=4)}
""")

# 3) quick FAQ
kb_texts.append("How to use the model: provide transaction features (Time, Amount, V1..V28) standardized; model outputs fraud probability.")
# ... gerekirse daha fazla ekle

# yazdÄ±r
for i,t in enumerate(kb_texts):
    print(f"--- DOC {i} ---")
    print(t[:400], "\n")

# HÃ¼cre 8: embeddings + FAISS
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import pickle

embed_model = SentenceTransformer('all-MiniLM-L6-v2')  # kÃ¼Ã§Ã¼k ve hÄ±zlÄ±
embeddings = embed_model.encode(kb_texts, show_progress_bar=True, convert_to_numpy=True)

# FAISS index
d = embeddings.shape[1]
index = faiss.IndexFlatL2(d)
index.add(embeddings)
faiss.write_index(index, 'kb_faiss.index')

# Kaydet: documents mapping
with open('kb_texts.pkl','wb') as f:
    pickle.dump(kb_texts, f)

print("FAISS index ve documents kaydedildi.")

!pip install faiss-cpu

# HÃ¼cre 9: RAG retrieval + OpenAI generation
import openai, os, pickle
from sentence_transformers import SentenceTransformer
import faiss
from sklearn.metrics.pairwise import cosine_similarity

# 1) OpenAI key
# os.environ['OPENAI_API_KEY'] = "sk-..."  # tercihen Colab Secrets ya da runtime environment varsÄ±na koy
OPENAI_API_KEY = os.getenv('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')
if OPENAI_API_KEY is None:
    print("UyarÄ±: OPENAI_API_KEY ortam deÄŸiÅŸkeni ayarlÄ± deÄŸil. Gradio'da kullanÄ±cÄ±dan alÄ±nacak ÅŸekilde de kurabilirsin.")
else:
    openai.api_key = OPENAI_API_KEY

# 2) yÃ¼kle index ve dokÃ¼manlar
index = faiss.read_index('kb_faiss.index')
with open('kb_texts.pkl','rb') as f:
    kb_texts = pickle.load(f)
embed_model = SentenceTransformer('all-MiniLM-L6-v2')

def retrieve_docs(query, top_k=2):
    q_emb = embed_model.encode([query], convert_to_numpy=True)
    D, I = index.search(q_emb, top_k)
    docs = [kb_texts[i] for i in I[0]]
    return docs

def generate_answer_with_openai(query):
    docs = retrieve_docs(query, top_k=3)
    context = "\n\n".join(docs)
    prompt = f"""You are an assistant for a Credit Card Fraud Detection project.
You have the following context from the project's knowledge base:
{context}

User question: {query}

Using the context, answer concisely and mention when answer is not in context.
"""
    if OPENAI_API_KEY is None:
        return "OpenAI API key not configured. Set OPENAI_API_KEY environment variable or use another LLM provider."
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",  # Ã¶rnek; kullanÄ±labilir modele gÃ¶re ayarla
        messages=[{"role":"system","content":"You are a helpful assistant."},
                  {"role":"user","content":prompt}],
        max_tokens=400,
        temperature=0.0
    )
    return resp['choices'][0]['message']['content']

# test
print(generate_answer_with_openai("What preprocessing is required for Amount?"))

# HÃ¼cre 10: Gradio RAG Chatbot
import gradio as gr

def rag_chat(user_input):
    # retrieval + generate
    docs = retrieve_docs(user_input, top_k=3)
    answer = generate_answer_with_openai(user_input)
    return answer + "\n\n---\nRetrieved docs (for transparency):\n" + "\n---\n".join(docs)

with gr.Blocks() as demo:
    gr.Markdown("## Fraud Detection â€” RAG Chatbot\nAsk about dataset, preprocessing, model, or how to use the classifier.")
    txt = gr.Textbox(label="Question", placeholder="Ask about preprocessing, model results, etc.")
    out = gr.Textbox(label="Answer")
    btn = gr.Button("Ask")
    btn.click(fn=rag_chat, inputs=txt, outputs=out)

demo.launch(share=True)

!pip install -U "huggingface_hub[cli]"
!huggingface-cli login

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import os
# import gradio as gr
# import openai
# import faiss
# import pickle
# from sentence_transformers import SentenceTransformer
# 
# # API anahtarÄ± (Hugging Face Secrets'ten otomatik alÄ±nÄ±r)
# openai.api_key = os.getenv("OPENAI_API_KEY")
# 
# # FAISS index ve knowledge base yÃ¼kleme
# try:
#     index = faiss.read_index("kb_faiss.index")
#     with open("kb_texts.pkl", "rb") as f:
#         kb_texts = pickle.load(f)
# except:
#     index = None
#     kb_texts = ["Bilgi tabanÄ± yÃ¼klenemedi."]
# 
# embedder = SentenceTransformer("all-MiniLM-L6-v2")
# 
# # RAG + LLM fonksiyonu
# def chat(query):
#     if index is not None:
#         q_emb = embedder.encode([query], convert_to_numpy=True)
#         D, I = index.search(q_emb, 1)
#         context = kb_texts[I[0][0]]
#     else:
#         context = "Knowledge base not found."
# 
#     prompt = f"""
#     You are a helpful assistant for a Credit Card Fraud Detection project.
#     Context: {context}
#     Question: {query}
#     """
# 
#     try:
#         response = openai.ChatCompletion.create(
#             model="gpt-4o-mini",
#             messages=[{"role": "user", "content": prompt}],
#             max_tokens=300,
#             temperature=0
#         )
#         return response.choices[0].message.content
#     except Exception as e:
#         return f"API error: {e}"
# 
# # Gradio arayÃ¼zÃ¼
# demo = gr.Interface(fn=chat, inputs="text", outputs="text",
#                     title="Fraud Detection Chatbot",
#                     description="RAG destekli dolandÄ±rÄ±cÄ±lÄ±k tespiti yardÄ±mcÄ±sÄ±.")
# 
# if __name__ == "__main__":
#     demo.launch()
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# gradio==4.44.0
# openai>=1.35.7
# faiss-cpu==1.7.4
# sentence-transformers==2.2.2
# torch==2.2.2
# numpy>=1.24.4
#

!huggingface-cli logout
!huggingface-cli login

!huggingface-cli whoami

!gradio deploy

from google.colab import files
files.download('app.py')
files.download('requirements.txt')
files.download('kb_faiss.index')
files.download('kb_texts.pkl')

# FAISS index ve bilgi tabanÄ± oluÅŸturma
import faiss, pickle
from sentence_transformers import SentenceTransformer

# Bilgi tabanÄ±na eklenecek Ã¶rnek bilgiler
kb_texts = [
    "Veri setinde toplam 284807 iÅŸlem vardÄ±r.",
    "Veri setindeki sÃ¼tunlar: Time, V1-V28, Amount ve Class.",
    "Class sÃ¼tunu 1 ise iÅŸlem dolandÄ±rÄ±cÄ±lÄ±ktÄ±r, 0 ise normaldir.",
    "Zaman sÃ¼tunu, her iÅŸlemin gerÃ§ekleÅŸtiÄŸi zamanÄ± saniye cinsinden gÃ¶sterir.",
    "V1-V28 sÃ¼tunlarÄ± PCA ile anonimleÅŸtirilmiÅŸ sayÄ±sal Ã¶zelliklerdir.",
    "Amount sÃ¼tunu, iÅŸlemin tutarÄ±nÄ± gÃ¶sterir."
]

embedder = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = embedder.encode(kb_texts, convert_to_numpy=True)

# FAISS index oluÅŸtur
dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(embeddings)
faiss.write_index(index, "kb_faiss.index")

# Text dosyasÄ±nÄ± kaydet
with open("kb_texts.pkl", "wb") as f:
    pickle.dump(kb_texts, f)

print("âœ… FAISS index ve bilgi tabanÄ± dosyalarÄ± oluÅŸturuldu!")

import pickle

kb_texts = [
    "Veri setinde toplam 284807 iÅŸlem vardÄ±r.",
    "Veri setindeki sÃ¼tunlar: Time, V1-V28, Amount ve Class.",
    "Class sÃ¼tunu 1 ise iÅŸlem dolandÄ±rÄ±cÄ±lÄ±ktÄ±r, 0 ise normaldir.",
    "Zaman sÃ¼tunu iÅŸlemin gerÃ§ekleÅŸtiÄŸi zamanÄ± saniye cinsinden gÃ¶sterir.",
    "V1-V28 sÃ¼tunlarÄ± PCA ile anonimleÅŸtirilmiÅŸ sayÄ±sal Ã¶zelliklerdir.",
    "Amount sÃ¼tunu, iÅŸlemin tutarÄ±nÄ± gÃ¶sterir.",
    "DolandÄ±rÄ±cÄ±lÄ±k iÅŸlemleri veri setinin Ã§ok kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± oluÅŸturur (dengesiz sÄ±nÄ±f problemi).",
    "Model performansÄ±nÄ± Ã¶lÃ§mek iÃ§in AUC-ROC ve precision-recall metrikleri kullanÄ±lÄ±r.",
    "Adli inceleme (forensic) iÃ§in iÅŸlem loglarÄ±, IP, cihaz ve zaman bilgileri analiz edilir."
]

with open("kb_texts.pkl", "wb") as f:
    pickle.dump(kb_texts, f)
print("Yeni kb_texts.pkl oluÅŸturuldu!")

import pickle
kb_texts = [
 "Veri setinde toplam 284807 iÅŸlem vardÄ±r.",
 "SÃ¼tunlar: Time, V1-V28, Amount, Class. Class=1 -> dolandÄ±rÄ±cÄ±lÄ±k, 0 -> normal.",
 "DolandÄ±rÄ±cÄ±lÄ±k Ã¶rnekleri veri setinin kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± oluÅŸturur; dengesiz sÄ±nÄ±f problemi vardÄ±r.",
 "V1-V28 PCA ile anonimleÅŸtirilmiÅŸ Ã¶zelliklerdir.",
 "Amount sÃ¼tunu iÅŸlem tutarÄ±nÄ± gÃ¶sterir.",
 "Adli inceleme iÃ§in iÅŸlem loglarÄ±, IP ve cihaz bilgileri ile zaman dizinleri analiz edilir.",
 "DolandÄ±rÄ±cÄ±lÄ±k tespitinde AUC-ROC ve precision-recall metrikleri kullanÄ±lÄ±r."
]
with open("kb_texts.pkl","wb") as f:
    pickle.dump(kb_texts,f)

import pickle
kb_texts = [
 "Veri setinde toplam 284807 iÅŸlem vardÄ±r.",
 "Veri setindeki sÃ¼tunlar: Time, V1-V28, Amount ve Class.",
 "Class sÃ¼tunu 1 ise iÅŸlem dolandÄ±rÄ±cÄ±lÄ±ktÄ±r, 0 ise normaldir.",
 "Zaman sÃ¼tunu iÅŸlemin gerÃ§ekleÅŸtiÄŸi zamanÄ± saniye cinsinden gÃ¶sterir.",
 "V1-V28 PCA ile anonimleÅŸtirilmiÅŸ sayÄ±sal Ã¶zelliklerdir.",
 "Amount sÃ¼tunu iÅŸlemin tutarÄ±nÄ± gÃ¶sterir.",
 "DolandÄ±rÄ±cÄ±lÄ±k iÅŸlemleri veri setinin kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± oluÅŸturur; dengesiz sÄ±nÄ±f problemi vardÄ±r.",
 "Model performansÄ±nÄ± Ã¶lÃ§mek iÃ§in AUC-ROC ve precision-recall metrikleri kullanÄ±lÄ±r.",
 "Adli inceleme iÃ§in iÅŸlem loglarÄ±, IP ve cihaz bilgileri analiz edilir."
]
with open("kb_texts.pkl","wb") as f:
    pickle.dump(kb_texts,f)

